# PBS configuration
# If submitting to a different project to your default uncomment line below 
# and change project code as appropriate
project: x77
queue: normal
walltime: 3:30:00
jobname: 01deg_jra55_ryf
ncpus: 5180

# Force payu to always find, and save, files in this short (or scratch) project directory
shortpath: /scratch/x77

# Model configuration
name: common
model: access-om2
input: /g/data/ik11/inputs/access-om2/input_08022019/common_01deg_jra55
submodels:
    - name: atmosphere
      model: yatm
      exe: /g/data/ik11/inputs/access-om2/bin/yatm_1bb8904.exe
      input: /g/data/ik11/inputs/access-om2/input_08022019/yatm_01deg
      ncpus: 1

    - name: ocean
      model: mom
      exe: /g/data/ik11/inputs/access-om2/bin/fms_ACCESS-OM_97e3429_libaccessom2_1bb8904.x
      input: /g/data/ik11/inputs/access-om2/input_08022019/mom_01deg
      ncpus: 4358

    - name: ice
      model: cice5
      exe: /g/data/ik11/inputs/access-om2/bin/cice_auscom_3600x2700_722p_d3e8bdf_libaccessom2_1bb8904.exe
      input: /g/data/ik11/inputs/access-om2/input_08022019/cice_01deg
      ncpus: 799

# Collation
collate:
  walltime: 10:00:00
  mem: 128GB
  ncpus: 4
  queue: express
  exe: /g/data/ik11/inputs/access-om2/bin/mppnccombine

# Misc
runlog: true
stacksize: unlimited
restart_freq: 1  # use tidy_restarts.py instead
# mpirun: --mca pml yalla -x MXM_LOG_FILE=$PBS_JOBFS/mxm.log
qsub_flags: -lother=hyperthread -W umask=027 # -l storage=gdata/ik11+scratch/x77+gdata/ua8+gdata/hh5
# set number of cores per node (28 for normalbw, 48 for normal on gadi)
mpi:
    module: openmpi/4.0.1


# DANGER! Do not uncomment this without checking the script is synching 
# to the correct location!
# postscript: sync_output_to_gdata.sh
